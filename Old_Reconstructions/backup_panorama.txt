import cv2
import numpy as np
import glob
import matplotlib.pyplot as plt
import scipy.io
import re
from scipy.ndimage import distance_transform_edt


def tryint(s):
    try:
        return int(s)
    except:
        return s

def alphanum_key(s):
    return [tryint(c) for c in re.split('([0-9]+)', s)]

# 1. Load distortion matrix from .mat file
mat = scipy.io.loadmat("C:/Users/franc/Desktop/Scuola/Measurement/advanced_measurments_project/dataset_medi/TARATURA/medium_dataset_taratura.mat")
camera_matrix = mat['K']
dist_coeffs = mat['dist']

# 2. Load all images
image_files = sorted(
    glob.glob("C:/Users/franc/Desktop/Scuola/Measurement/advanced_measurments_project/dataset_medi/Scorre_nappies/*.png"),
    key=alphanum_key)
frames = [cv2.imread(f, cv2.IMREAD_COLOR) for f in image_files]
frames = [f for f in frames if f is not None and f.shape == frames[0].shape]

# 3. Undistort all images
frames = [
    cv2.undistort(f, camera_matrix, dist_coeffs) for f in frames
]

# --- Crop each frame to 1214x877 centered in the image ---
crop_w, crop_h = 1214, 877
H, W, C = frames[0].shape
center_x, center_y = W // 2, H // 2
x1 = center_x - crop_w // 2
y1 = center_y - crop_h // 2
x2 = x1 + crop_w
y2 = y1 + crop_h
frames = [f[y1:y2, x1:x2] for f in frames]
H, W, C = frames[0].shape

# 4. ORB feature matcher setup
orb = cv2.ORB_create(1000)
bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)

# --- Compute cumulative affine transforms ---
transforms = [np.eye(3, dtype=np.float32)]  # 3x3 identity for homogenous coordinates

for i in range(1, len(frames)):
    img1 = frames[i-1]
    img2 = frames[i]
    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

    kp1, des1 = orb.detectAndCompute(gray1, None)
    kp2, des2 = orb.detectAndCompute(gray2, None)
    if des1 is None or des2 is None or len(kp1) < 4 or len(kp2) < 4:
        print(f"Skipping frame {i} due to insufficient features.")
        transforms.append(transforms[-1].copy())
        continue

    matches = bf.match(des1, des2)
    matches = sorted(matches, key=lambda x: x.distance)
    good_matches = matches[:10]

    src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1,2)
    dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1,2)

    # Estimate affine transform (from img2 to img1, so we can "undo" the carton movement)
    M, inliers = cv2.estimateAffinePartial2D(dst_pts, src_pts, method=cv2.RANSAC)
    if M is None:
        print(f"Skipping frame {i} due to failed affine estimation.")
        transforms.append(transforms[-1].copy())
        continue

    # Convert 2x3 affine to 3x3
    M33 = np.eye(3, dtype=np.float32)
    M33[:2, :3] = M

    # Compose with previous transform
    cumulative = transforms[-1] @ M33
    transforms.append(cumulative)
    print(f"Frame {i}: Affine matrix:\n{M}")

# --- Compute panorama size ---
# Warp the corners of each image to find the panorama bounds
corners = np.array([
    [0, 0, 1],
    [W, 0, 1],
    [W, H, 1],
    [0, H, 1]
], dtype=np.float32)

all_corners = []
for T in transforms:
    warped = (T @ corners.T).T
    all_corners.append(warped[:, :2])

all_corners = np.vstack(all_corners)
x_min, y_min = np.floor(all_corners.min(axis=0)).astype(int)
x_max, y_max = np.ceil(all_corners.max(axis=0)).astype(int)

panorama_width = x_max - x_min
panorama_height = y_max - y_min

# --- Blend images into panorama using affine warps ---
panorama_sum = np.zeros((panorama_height, panorama_width, C), dtype=np.float32)
panorama_count = np.zeros((panorama_height, panorama_width), dtype=np.float32)

for i, img in enumerate(frames):
    # Offset transform so panorama starts at (0,0)
    offset_M = transforms[i].copy()
    offset_M[0,2] -= x_min
    offset_M[1,2] -= y_min

    warped = cv2.warpAffine(img, offset_M[:2], (panorama_width, panorama_height))
    mask = cv2.warpAffine(
        (np.any(img > 10, axis=2)).astype(np.uint8),
        offset_M[:2], (panorama_width, panorama_height)
    ).astype(bool)

    for c in range(C):
        panorama_sum[..., c][mask] += warped[..., c][mask]
    panorama_count[mask] += 1

# Avoid division by zero
panorama_count[panorama_count == 0] = 1
panorama_avg = (panorama_sum / panorama_count[..., None]).astype(np.uint8)


# Crop to non-empty region (optional)
gray_panorama = cv2.cvtColor(panorama_avg, cv2.COLOR_BGR2GRAY)
coords = cv2.findNonZero((gray_panorama > 0).astype(np.uint8))
x, y, w, h = cv2.boundingRect(coords)
panorama_cropped = panorama_avg[y:y+h, x:x+w]

# Show the result
plt.figure(figsize=(15, 8))
plt.imshow(cv2.cvtColor(panorama_cropped, cv2.COLOR_BGR2RGB))
plt.axis('off')
plt.title("Reconstructed Subject (Affine)")
plt.show()